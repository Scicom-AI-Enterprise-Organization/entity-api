# Flash Attention Encoder Non-Causal API requirements
torch>=2.0.0
transformers>=4.40.0
flash-attn>=2.5.0  # FA3 on Hopper (H100), FA2 on Ampere (A100)
fastapi>=0.100.0
uvicorn>=0.23.0
uvloop>=0.19.0
pydantic>=2.0.0
accelerate>=0.25.0
aiohttp>=3.8.0
click>=8.0.0